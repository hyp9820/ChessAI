{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-chess==0.31.3\n",
      "  Using cached python_chess-0.31.3-py3-none-any.whl (134 kB)\n",
      "Installing collected packages: python-chess\n",
      "Successfully installed python-chess-0.31.3\n"
     ]
    }
   ],
   "source": [
    "!pip install python-chess==0.31.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.1-cp38-cp38-win_amd64.whl (370.7 MB)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.16.0-py2.py3-none-any.whl (173 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\saaransh\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\saaransh\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Collecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\saaransh\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\saaransh\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\saaransh\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Processing c:\\users\\saaransh\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\\termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.30.0-py2.py3-none-any.whl (146 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\saaransh\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\saaransh\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\saaransh\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (50.3.1.post20201107)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\saaransh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\saaransh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saaransh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\saaransh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Building wheels for collected packages: wrapt\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19558 sha256=906704427711d5fff4da501cd6c678f79006c76b8c1cbb3d472b142e58cc0817\n",
      "  Stored in directory: c:\\users\\saaransh\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built wrapt\n",
      "Installing collected packages: grpcio, protobuf, markdown, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, absl-py, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, tensorboard, wrapt, tensorflow-estimator, opt-einsum, gast, flatbuffers, keras-preprocessing, astunparse, google-pasta, termcolor, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed absl-py-0.12.0 astunparse-1.6.3 cachetools-4.2.2 flatbuffers-1.12 gast-0.3.3 google-auth-1.30.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.16.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stockfish\n",
      "  Using cached stockfish-3.14.0-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: stockfish\n",
      "Successfully installed stockfish-3.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stockfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chess\n",
    "\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.utils as utils\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "\n",
    "from stockfish import Stockfish\n",
    "\n",
    "stockfish = Stockfish(r\"stockfish_13_win_x64_bmi2/stockfish_13_win_x64_bmi2\")\n",
    "# stockfish.set_skill_level(1)\n",
    "stockfish.set_elo_rating(500)\n",
    "stockfish.set_depth(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500000, 8, 8, 14)\n",
      "(1500000,)\n"
     ]
    }
   ],
   "source": [
    "def get_dataset():\n",
    "    container = np.load('dataset.npz')\n",
    "    b, v = container['b'], container['v']\n",
    "    v = np.asarray(v / abs(v).max() / 2 + 0.5, dtype=np.float32) # normalization (0 - 1)\n",
    "    return b, v\n",
    "\n",
    "\n",
    "x_train, y_train = get_dataset()\n",
    "x_train = np.swapaxes(x_train, -1, 1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(conv_size, conv_depth):\n",
    "    board3d = layers.Input(shape=(8, 8, 14))\n",
    "    \n",
    "    x = board3d\n",
    "    for _ in range(conv_depth):\n",
    "        x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', activation='relu', data_format='channels_last')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, 'relu')(x)\n",
    "    x = layers.Dense(1, 'sigmoid')(x)\n",
    "\n",
    "    return models.Model(inputs=board3d, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 8, 8, 14)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 32)          4064      \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 163,009\n",
      "Trainable params: 163,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(32, 4)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 8, 8, 14)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 32)          4064      \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 163,009\n",
      "Trainable params: 163,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "660/660 [==============================] - 283s 429ms/step - loss: 0.0011 - val_loss: 6.6218e-04\n",
      "Epoch 2/500\n",
      "660/660 [==============================] - 286s 434ms/step - loss: 5.5243e-04 - val_loss: 4.9835e-04\n",
      "Epoch 3/500\n",
      "660/660 [==============================] - 288s 436ms/step - loss: 4.6521e-04 - val_loss: 4.3894e-04\n",
      "Epoch 4/500\n",
      "660/660 [==============================] - 289s 438ms/step - loss: 4.1690e-04 - val_loss: 4.1167e-04\n",
      "Epoch 5/500\n",
      "660/660 [==============================] - 289s 439ms/step - loss: 3.8886e-04 - val_loss: 4.0023e-04\n",
      "Epoch 6/500\n",
      "660/660 [==============================] - 287s 434ms/step - loss: 3.6696e-04 - val_loss: 3.6969e-04\n",
      "Epoch 7/500\n",
      "660/660 [==============================] - 301s 457ms/step - loss: 3.4577e-04 - val_loss: 3.6295e-04\n",
      "Epoch 8/500\n",
      "660/660 [==============================] - 285s 431ms/step - loss: 3.3155e-04 - val_loss: 3.4430e-04\n",
      "Epoch 9/500\n",
      "660/660 [==============================] - 289s 438ms/step - loss: 3.1650e-04 - val_loss: 3.4046e-04\n",
      "Epoch 10/500\n",
      "660/660 [==============================] - 291s 441ms/step - loss: 3.0510e-04 - val_loss: 3.1357e-04\n",
      "Epoch 11/500\n",
      "660/660 [==============================] - 290s 439ms/step - loss: 2.9397e-04 - val_loss: 3.4687e-04\n",
      "Epoch 12/500\n",
      "660/660 [==============================] - 288s 436ms/step - loss: 2.8583e-04 - val_loss: 3.1559e-04\n",
      "Epoch 13/500\n",
      "660/660 [==============================] - 288s 436ms/step - loss: 2.7660e-04 - val_loss: 3.9095e-04\n",
      "Epoch 14/500\n",
      "660/660 [==============================] - 286s 434ms/step - loss: 2.6970e-04 - val_loss: 2.9958e-04\n",
      "Epoch 15/500\n",
      "660/660 [==============================] - 293s 444ms/step - loss: 2.6487e-04 - val_loss: 3.1052e-04\n",
      "Epoch 16/500\n",
      "660/660 [==============================] - 293s 444ms/step - loss: 2.5416e-04 - val_loss: 3.0109e-04\n",
      "Epoch 17/500\n",
      "660/660 [==============================] - 295s 447ms/step - loss: 2.5258e-04 - val_loss: 3.4373e-04\n",
      "Epoch 18/500\n",
      "660/660 [==============================] - 295s 447ms/step - loss: 2.4510e-04 - val_loss: 2.8123e-04\n",
      "Epoch 19/500\n",
      "660/660 [==============================] - 313s 474ms/step - loss: 2.3830e-04 - val_loss: 2.8502e-04\n",
      "Epoch 20/500\n",
      "660/660 [==============================] - 323s 489ms/step - loss: 2.1137e-04 - val_loss: 2.7118e-04\n",
      "Epoch 21/500\n",
      "660/660 [==============================] - 314s 476ms/step - loss: 2.0884e-04 - val_loss: 2.6933e-04\n",
      "Epoch 22/500\n",
      "660/660 [==============================] - 308s 467ms/step - loss: 2.0802e-04 - val_loss: 2.8376e-04\n",
      "Epoch 23/500\n",
      "660/660 [==============================] - 315s 477ms/step - loss: 2.0725e-04 - val_loss: 2.7314e-04\n",
      "Epoch 24/500\n",
      "660/660 [==============================] - 319s 483ms/step - loss: 2.0607e-04 - val_loss: 2.6937e-04\n",
      "Epoch 25/500\n",
      "660/660 [==============================] - 306s 464ms/step - loss: 2.0501e-04 - val_loss: 2.6950e-04\n",
      "Epoch 26/500\n",
      "660/660 [==============================] - 311s 472ms/step - loss: 2.0422e-04 - val_loss: 2.7150e-04\n",
      "Epoch 27/500\n",
      "660/660 [==============================] - 286s 434ms/step - loss: 2.0287e-04 - val_loss: 2.7321e-04\n",
      "Epoch 28/500\n",
      "660/660 [==============================] - 286s 433ms/step - loss: 2.0201e-04 - val_loss: 2.7139e-04\n",
      "Epoch 29/500\n",
      "660/660 [==============================] - 286s 433ms/step - loss: 2.0087e-04 - val_loss: 2.7339e-04\n",
      "Epoch 30/500\n",
      "660/660 [==============================] - 286s 433ms/step - loss: 2.0026e-04 - val_loss: 2.6987e-04\n",
      "Epoch 31/500\n",
      "660/660 [==============================] - 291s 441ms/step - loss: 1.9608e-04 - val_loss: 2.6819e-04\n",
      "Epoch 32/500\n",
      "660/660 [==============================] - 315s 477ms/step - loss: 1.9585e-04 - val_loss: 2.6904e-04\n",
      "Epoch 33/500\n",
      "660/660 [==============================] - 310s 470ms/step - loss: 1.9576e-04 - val_loss: 2.6750e-04\n",
      "Epoch 34/500\n",
      "660/660 [==============================] - 288s 437ms/step - loss: 1.9561e-04 - val_loss: 2.6887e-04\n",
      "Epoch 35/500\n",
      "660/660 [==============================] - 292s 442ms/step - loss: 1.9551e-04 - val_loss: 2.6860e-04\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate= 0.0005), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=2048,\n",
    "          epochs=500,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n",
    "\n",
    "model.save('model_three.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8, 8, 14)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 8, 8, 32)          4064      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 163,009\n",
      "Trainable params: 163,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mymodel = models.load_model('fiftyepochs.h5')\n",
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares_index = {\n",
    "  'a': 0,\n",
    "  'b': 1,\n",
    "  'c': 2,\n",
    "  'd': 3,\n",
    "  'e': 4,\n",
    "  'f': 5,\n",
    "  'g': 6,\n",
    "  'h': 7\n",
    "}\n",
    "\n",
    "\n",
    "# example: h3 -> 17\n",
    "def square_to_index(square):\n",
    "  letter = chess.square_name(square)\n",
    "  return 8 - int(letter[1]), squares_index[letter[0]]\n",
    "\n",
    "\n",
    "def split_dims(board):\n",
    "  # this is the 3d matrix\n",
    "  board3d = np.zeros((8, 8, 14), dtype=np.int8)\n",
    "\n",
    "  # here we add the pieces's view on the matrix\n",
    "  for piece in chess.PIECE_TYPES:\n",
    "    for square in board.pieces(piece, chess.WHITE):\n",
    "      idx = np.unravel_index(square, (8, 8))\n",
    "      board3d[7 - idx[0]][idx[1]][piece - 1] = 1\n",
    "    for square in board.pieces(piece, chess.BLACK):\n",
    "      idx = np.unravel_index(square, (8, 8))\n",
    "      board3d[7 - idx[0]][idx[1]][piece + 5] = 1\n",
    "\n",
    "  # add attacks and valid moves too\n",
    "  # so the network knows what is being attacked\n",
    "  aux = board.turn\n",
    "  board.turn = chess.WHITE\n",
    "  for move in board.legal_moves:\n",
    "      i, j = square_to_index(move.to_square)\n",
    "      board3d[i][j][12] = 1\n",
    "  board.turn = chess.BLACK\n",
    "  for move in board.legal_moves:\n",
    "      i, j = square_to_index(move.to_square)\n",
    "      board3d[i][j][13] = 1\n",
    "  board.turn = aux\n",
    "\n",
    "  return board3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for the minimax algorithm\n",
    "def minimax_eval(board):\n",
    "  board3d = split_dims(board)\n",
    "  board3d = np.expand_dims(board3d, 0)\n",
    "  return mymodel.predict(board3d)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(board, depth, alpha, beta, maximizing_player):\n",
    "  if depth == 0 or board.is_game_over():\n",
    "    return minimax_eval(board)\n",
    "  \n",
    "  if maximizing_player:\n",
    "    max_eval = -np.inf\n",
    "    for move in board.legal_moves:\n",
    "      board.push(move)\n",
    "      eval = minimax(board, depth - 1, alpha, beta, False)\n",
    "      board.pop()\n",
    "      max_eval = max(max_eval, eval)\n",
    "      alpha = max(alpha, eval)\n",
    "      if beta <= alpha:\n",
    "        break\n",
    "    return max_eval\n",
    "  else:\n",
    "    min_eval = np.inf\n",
    "    for move in board.legal_moves:\n",
    "      board.push(move)\n",
    "      eval = minimax(board, depth - 1, alpha, beta, True)\n",
    "      board.pop()\n",
    "      min_eval = min(min_eval, eval)\n",
    "      beta = min(beta, eval)\n",
    "      if beta <= alpha:\n",
    "        break\n",
    "    return min_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the actual function that gets the move from the neural network\n",
    "def get_ai_move(board, depth, color):\n",
    "    best_move = None\n",
    "    max_eval = -np.inf\n",
    "    min_eval = np.inf\n",
    "\n",
    "\n",
    "\n",
    "    for move in board.legal_moves:\n",
    "        board.push(move)\n",
    "        eval = minimax(board, depth - 1, -np.inf, np.inf, False)\n",
    "        board.pop()\n",
    "        if color == \"white\":\n",
    "            if eval > max_eval:\n",
    "              max_eval = eval\n",
    "              best_move = move\n",
    "        elif color == \"black\":\n",
    "            if eval < min_eval:\n",
    "              min_eval = eval\n",
    "              best_move = move\n",
    "\n",
    "    return best_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move: 1 ----------\n",
      "\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "\n",
      "Move: 2 ----------\n",
      "\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . . . Q .\n",
      ". . . . P . . .\n",
      "P P P P . P P P\n",
      "R N B . K B N R\n",
      "\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . . . Q .\n",
      ". . . . P . . .\n",
      "P P P P . P P P\n",
      "R N B . K B N R\n",
      "\n",
      "Move: 3 ----------\n",
      "\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . . . Q .\n",
      ". . . . P N . .\n",
      "P P P P . P P P\n",
      "R N B . K B . R\n",
      "\n",
      "r . b q k b n r\n",
      "p p p p . p p .\n",
      ". . n . . . . .\n",
      ". . . . p . . p\n",
      ". . . . . . Q .\n",
      ". . . . P N . .\n",
      "P P P P . P P P\n",
      "R N B . K B . R\n",
      "\n",
      "Move: 4 ----------\n",
      "\n",
      "r . b q k b n r\n",
      "p p p p . p p .\n",
      ". . n . . . . .\n",
      ". . . . p Q . p\n",
      ". . . . . . . .\n",
      ". . . . P N . .\n",
      "P P P P . P P P\n",
      "R N B . K B . R\n",
      "\n",
      "r . b q k b . r\n",
      "p p p p . p p .\n",
      ". . n . . n . .\n",
      ". . . . p Q . p\n",
      ". . . . . . . .\n",
      ". . . . P N . .\n",
      "P P P P . P P P\n",
      "R N B . K B . R\n",
      "\n",
      "Move: 5 ----------\n",
      "\n",
      "r . b q k b . r\n",
      "p p p p . p p .\n",
      ". . n . . n . .\n",
      ". . . . p . Q p\n",
      ". . . . . . . .\n",
      ". . . . P N . .\n",
      "P P P P . P P P\n",
      "R N B . K B . R\n",
      "\n",
      "r . b q k b . r\n",
      "p p p . . p p .\n",
      ". . n . . n . .\n",
      ". . . p p . Q p\n",
      ". . . . . . . .\n",
      ". . . . P N . .\n",
      "P P P P . P P P\n",
      "R N B . K B . R\n",
      "\n",
      "Move: 6 ----------\n",
      "\n",
      "r . b q k b . r\n",
      "p p p . . p p .\n",
      ". . n . . n . .\n",
      ". . . p p . Q p\n",
      ". . . . . . . .\n",
      ". . N . P N . .\n",
      "P P P P . P P P\n",
      "R . B . K B . R\n",
      "\n",
      "r . b q k b . r\n",
      "p p p . . p p .\n",
      ". . n . . n . .\n",
      ". . . p p . Q .\n",
      ". . . . . . . p\n",
      ". . N . P N . .\n",
      "P P P P . P P P\n",
      "R . B . K B . R\n",
      "\n",
      "Move: 7 ----------\n",
      "\n",
      "r . b q k b . r\n",
      "p p p . . p p .\n",
      ". . n . . n . .\n",
      ". . . p p . Q .\n",
      ". . . . . . . p\n",
      ". . N B P N . .\n",
      "P P P P . P P P\n",
      "R . B . K . . R\n",
      "\n",
      "r . b q k b . r\n",
      "p p p . . p p .\n",
      ". . n . . n . .\n",
      ". . . p p . Q .\n",
      ". . . . . . . .\n",
      ". . N B P N . p\n",
      "P P P P . P P P\n",
      "R . B . K . . R\n",
      "\n",
      "Move: 8 ----------\n",
      "\n",
      "r . b q k b . r\n",
      "p p p . . p p .\n",
      ". . n . . n . .\n",
      ". . . p p . Q .\n",
      ". . . . . . . .\n",
      ". . N B P N . P\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "r . b q k b . r\n",
      "p p p . . p p .\n",
      ". . n . . n . .\n",
      ". . . . p . Q .\n",
      ". . . p . . . .\n",
      ". . N B P N . P\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "Move: 9 ----------\n",
      "\n",
      "r . b q k b . r\n",
      "p p p . . p p .\n",
      ". . n . . n . .\n",
      ". . . . p . Q .\n",
      ". . . P . . . .\n",
      ". . N B . N . P\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "r . . q k b . r\n",
      "p p p . . p p .\n",
      ". . n . . n . .\n",
      ". . . . p . Q .\n",
      ". . . P . . . .\n",
      ". . N B . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "Move: 10 ----------\n",
      "\n",
      "r . . q k b . r\n",
      "p p p . . p p .\n",
      ". . n . . n . .\n",
      ". B . . p . Q .\n",
      ". . . P . . . .\n",
      ". . N . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "r . . q k b . r\n",
      "p p p . . p p .\n",
      ". . n . . n . .\n",
      ". B . . . . Q .\n",
      ". . . P p . . .\n",
      ". . N . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "Move: 11 ----------\n",
      "\n",
      "r . . q k b . r\n",
      "p p p . . p p .\n",
      ". . B . . n . .\n",
      ". . . . . . Q .\n",
      ". . . P p . . .\n",
      ". . N . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "r . . q k b . r\n",
      "p . p . . p p .\n",
      ". . p . . n . .\n",
      ". . . . . . Q .\n",
      ". . . P p . . .\n",
      ". . N . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "Move: 12 ----------\n",
      "\n",
      "r . . q k b . r\n",
      "p . p . . p p .\n",
      ". . p . . n . .\n",
      ". . . . . . Q .\n",
      ". . . P N . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "r . . q k . . r\n",
      "p . p . b p p .\n",
      ". . p . . n . .\n",
      ". . . . . . Q .\n",
      ". . . P N . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "Move: 13 ----------\n",
      "\n",
      "r . . q k . . r\n",
      "p . p . b p Q .\n",
      ". . p . . n . .\n",
      ". . . . . . . .\n",
      ". . . P N . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "r . . q k . . .\n",
      "p . p . b p Q .\n",
      ". . p . . n . .\n",
      ". . . . . . . r\n",
      ". . . P N . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "Move: 14 ----------\n",
      "\n",
      "r . . q k . . .\n",
      "p . p . b p Q .\n",
      ". . p . . N . .\n",
      ". . . . . . . r\n",
      ". . . P . . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "r . . q k . . .\n",
      "p . p . . p Q .\n",
      ". . p . . b . .\n",
      ". . . . . . . r\n",
      ". . . P . . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "Move: 15 ----------\n",
      "\n",
      "r . . q k . Q .\n",
      "p . p . . p . .\n",
      ". . p . . b . .\n",
      ". . . . . . . r\n",
      ". . . P . . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "r . . q . . Q .\n",
      "p . p k . p . .\n",
      ". . p . . b . .\n",
      ". . . . . . . r\n",
      ". . . P . . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "Move: 16 ----------\n",
      "\n",
      "r . . q . . . .\n",
      "p . p k . Q . .\n",
      ". . p . . b . .\n",
      ". . . . . . . r\n",
      ". . . P . . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "r . . . . . . .\n",
      "p . p k q Q . .\n",
      ". . p . . b . .\n",
      ". . . . . . . r\n",
      ". . . P . . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "Move: 17 ----------\n",
      "\n",
      "r . . . . . . .\n",
      "p . p k Q . . .\n",
      ". . p . . b . .\n",
      ". . . . . . . r\n",
      ". . . P . . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "r . . . . . . .\n",
      "p . p k b . . .\n",
      ". . p . . . . .\n",
      ". . . . . . . r\n",
      ". . . P . . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "Move: 18 ----------\n",
      "\n",
      "r . . . . . . .\n",
      "p . p k b . . .\n",
      ". . p . . . . .\n",
      ". . . P . . . r\n",
      ". . . . . . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      ". . . . . r . .\n",
      "p . p k b . . .\n",
      ". . p . . . . .\n",
      ". . . P . . . r\n",
      ". . . . . . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "Move: 19 ----------\n",
      "\n",
      ". . . . . r . .\n",
      "p . p k b . . .\n",
      ". . P . . . . .\n",
      ". . . . . . . r\n",
      ". . . . . . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      ". . . . . r . .\n",
      "p . p . b . . .\n",
      ". . P k . . . .\n",
      ". . . . . . . r\n",
      ". . . . . . . .\n",
      ". . . . . N . b\n",
      "P P P P . P . P\n",
      "R . B . K . . R\n",
      "\n",
      "Move: 20 ----------\n",
      "\n",
      ". . . . . r . .\n",
      "p . p . b . . .\n",
      ". . P k . . . .\n",
      ". . . . . . . r\n",
      ". . . . . . . .\n",
      ". . . . . N . b\n",
      "P P P P K P . P\n",
      "R . B . . . . R\n",
      "\n",
      ". . . . r . . .\n",
      "p . p . b . . .\n",
      ". . P k . . . .\n",
      ". . . . . . . r\n",
      ". . . . . . . .\n",
      ". . . . . N . b\n",
      "P P P P K P . P\n",
      "R . B . . . . R\n",
      "\n",
      "Move: 21 ----------\n",
      "\n",
      ". . . . r . . .\n",
      "p . p . b . . .\n",
      ". . P k . . . .\n",
      ". . . . . . . r\n",
      ". . . . . . . .\n",
      ". . . K . N . b\n",
      "P P P P . P . P\n",
      "R . B . . . . R\n",
      "\n",
      ". . . . r . . .\n",
      "p . p . b . . .\n",
      ". . P k . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . K . N . b\n",
      "P P P P . P . P\n",
      "R . B . . . . R\n",
      "\n",
      "Move: 22 ----------\n",
      "\n",
      ". . . . r . . .\n",
      "p . p . b . . .\n",
      ". . P k . . . .\n",
      ". . . r . . . .\n",
      ". . . N . . . .\n",
      ". . . K . . . b\n",
      "P P P P . P . P\n",
      "R . B . . . . R\n",
      "\n",
      ". . . . r . . .\n",
      "p . p . . . . .\n",
      ". . P k . b . .\n",
      ". . . r . . . .\n",
      ". . . N . . . .\n",
      ". . . K . . . b\n",
      "P P P P . P . P\n",
      "R . B . . . . R\n",
      "\n",
      "Move: 23 ----------\n",
      "\n",
      ". . . . r . . .\n",
      "p . p . . . . .\n",
      ". . P k . b . .\n",
      ". . . r . . . .\n",
      ". . . N . . . .\n",
      ". . P K . . . b\n",
      "P P . P . P . P\n",
      "R . B . . . . R\n",
      "\n",
      ". . . . r . . .\n",
      "p . p . . . . .\n",
      ". . P k . b . .\n",
      ". . . r . . . .\n",
      ". . . N . . b .\n",
      ". . P K . . . .\n",
      "P P . P . P . P\n",
      "R . B . . . . R\n",
      "\n",
      "Move: 24 ----------\n",
      "\n",
      ". . . . r . . .\n",
      "p . p . . . . .\n",
      ". . P k . b . .\n",
      ". . . r . . . .\n",
      ". . . N . . b .\n",
      ". . P K . . . P\n",
      "P P . P . P . .\n",
      "R . B . . . . R\n",
      "\n",
      ". . . . r . . .\n",
      "p . p . . . . .\n",
      ". . P k . b . .\n",
      ". . . r . . . .\n",
      ". . . N . . . .\n",
      ". . P K . b . P\n",
      "P P . P . P . .\n",
      "R . B . . . . R\n",
      "\n",
      "Move: 25 ----------\n",
      "\n",
      ". . . . r . . .\n",
      "p . p . . . . .\n",
      ". . P k . b . .\n",
      ". . . r . . . .\n",
      ". . . N . . . .\n",
      ". . P K . b . P\n",
      "P P . P . P . .\n",
      "R . B . . . R .\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P k . b . .\n",
      ". . . r . . . .\n",
      ". . . N . . . .\n",
      ". . P K . b . P\n",
      "P P . P . P . .\n",
      "R . B . . . R .\n",
      "\n",
      "Move: 26 ----------\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P k . b . .\n",
      ". . . r . . . .\n",
      ". . . N . . . .\n",
      ". . P K . b R P\n",
      "P P . P . P . .\n",
      "R . B . . . . .\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P k . b . .\n",
      ". . . r . . . .\n",
      ". . . N b . . .\n",
      ". . P K . . R P\n",
      "P P . P . P . .\n",
      "R . B . . . . .\n",
      "\n",
      "Move: 27 ----------\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P k . b . .\n",
      ". . . r . . . .\n",
      ". . . N b . . .\n",
      ". . P . . . R P\n",
      "P P . P K P . .\n",
      "R . B . . . . .\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P k . b b .\n",
      ". . . r . . . .\n",
      ". . . N . . . .\n",
      ". . P . . . R P\n",
      "P P . P K P . .\n",
      "R . B . . . . .\n",
      "\n",
      "Move: 28 ----------\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P k . b b .\n",
      ". . . r . . . .\n",
      ". . . N . . . .\n",
      ". . P . . . R P\n",
      "P P . P . P . .\n",
      "R . B . . K . .\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P k . b . .\n",
      ". . . r . b . .\n",
      ". . . N . . . .\n",
      ". . P . . . R P\n",
      "P P . P . P . .\n",
      "R . B . . K . .\n",
      "\n",
      "Move: 29 ----------\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P k . b . .\n",
      ". . . r . N . .\n",
      ". . . . . . . .\n",
      ". . P . . . R P\n",
      "P P . P . P . .\n",
      "R . B . . K . .\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P k . b . .\n",
      ". . . . . r . .\n",
      ". . . . . . . .\n",
      ". . P . . . R P\n",
      "P P . P . P . .\n",
      "R . B . . K . .\n",
      "\n",
      "Move: 30 ----------\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P k . b . .\n",
      ". . . . . r . .\n",
      ". . . . . . . .\n",
      ". P P . . . R P\n",
      "P . . P . P . .\n",
      "R . B . . K . .\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P . . b . .\n",
      ". . . k . r . .\n",
      ". . . . . . . .\n",
      ". P P . . . R P\n",
      "P . . P . P . .\n",
      "R . B . . K . .\n",
      "\n",
      "Move: 31 ----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P . . b . .\n",
      ". . . k . r . .\n",
      ". . . . . . . .\n",
      "B P P . . . R P\n",
      "P . . P . P . .\n",
      "R . . . . K . .\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P . . . . .\n",
      ". . . k . r b .\n",
      ". . . . . . . .\n",
      "B P P . . . R P\n",
      "P . . P . P . .\n",
      "R . . . . K . .\n",
      "\n",
      "Move: 32 ----------\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P . . . . .\n",
      ". . . k . r b .\n",
      ". . P . . . . .\n",
      "B P . . . . R P\n",
      "P . . P . P . .\n",
      "R . . . . K . .\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P . . . . .\n",
      ". . . . . r b .\n",
      ". . P k . . . .\n",
      "B P . . . . R P\n",
      "P . . P . P . .\n",
      "R . . . . K . .\n",
      "\n",
      "Move: 33 ----------\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P . . . . .\n",
      ". . . . . r b .\n",
      ". . P k . . R .\n",
      "B P . . . . . P\n",
      "P . . P . P . .\n",
      "R . . . . K . .\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P . . . . .\n",
      ". . . . . . b .\n",
      ". . P k . r R .\n",
      "B P . . . . . P\n",
      "P . . P . P . .\n",
      "R . . . . K . .\n",
      "\n",
      "Move: 34 ----------\n",
      "\n",
      ". . . . r . . .\n",
      ". . p . . . . .\n",
      "p . P . . . . .\n",
      ". . . . . . R .\n",
      ". . P k . r . .\n",
      "B P . . . . . P\n",
      "P . . P . P . .\n",
      "R . . . . K . .\n",
      "\n",
      ". r . . . . . .\n",
      ". . p . . . . .\n",
      "p . P . . . . .\n",
      ". . . . . . R .\n",
      ". . P k . r . .\n",
      "B P . . . . . P\n",
      "P . . P . P . .\n",
      "R . . . . K . .\n",
      "\n",
      "Move: 35 ----------\n",
      "\n",
      ". r . . . . . .\n",
      ". . p . . . . .\n",
      "p . P . . . . .\n",
      ". . B . . . R .\n",
      ". . P k . r . .\n",
      ". P . . . . . P\n",
      "P . . P . P . .\n",
      "R . . . . K . .\n",
      "\n",
      ". r . . . . . .\n",
      ". . p . . . . .\n",
      "p . P . . . . .\n",
      ". . B . . . R .\n",
      ". . P . k r . .\n",
      ". P . . . . . P\n",
      "P . . P . P . .\n",
      "R . . . . K . .\n",
      "\n",
      "Move: 36 ----------\n",
      "\n",
      ". r . . . . . .\n",
      "B . p . . . . .\n",
      "p . P . . . . .\n",
      ". . . . . . R .\n",
      ". . P . k r . .\n",
      ". P . . . . . P\n",
      "P . . P . P . .\n",
      "R . . . . K . .\n",
      "\n",
      ". . . . . . . .\n",
      "B . p . . . . .\n",
      "p . P . . . . .\n",
      ". . . . . . R .\n",
      ". r P . k r . .\n",
      ". P . . . . . P\n",
      "P . . P . P . .\n",
      "R . . . . K . .\n",
      "\n",
      "Move: 37 ----------\n",
      "\n",
      ". . . . . . . .\n",
      "B . p . . . . .\n",
      "p . P . . . . .\n",
      ". . . . . . R .\n",
      ". r P . k r . .\n",
      ". P . . . . . P\n",
      "P . . P K P . .\n",
      "R . . . . . . .\n",
      "\n",
      ". . . . . . . .\n",
      "B . p . . . . .\n",
      "p . P . . r . .\n",
      ". . . . . . R .\n",
      ". r P . k . . .\n",
      ". P . . . . . P\n",
      "P . . P K P . .\n",
      "R . . . . . . .\n",
      "\n",
      "Move: 38 ----------\n",
      "\n",
      ". . . . . . . .\n",
      "B . p . . . . .\n",
      "p . P . . r . .\n",
      ". . . . . . R .\n",
      ". r P . k . . .\n",
      ". P . P . . . P\n",
      "P . . . K P . .\n",
      "R . . . . . . .\n",
      "\n",
      ". . . . . . . .\n",
      "B . p . . . . .\n",
      "p . P . . r . .\n",
      ". . . . . . R .\n",
      ". r P . . k . .\n",
      ". P . P . . . P\n",
      "P . . . K P . .\n",
      "R . . . . . . .\n",
      "\n",
      "Move: 39 ----------\n",
      "\n",
      ". . . . . . . .\n",
      ". . p . . . . .\n",
      "p . P . . r . .\n",
      ". . . . . . R .\n",
      ". r P . . k . .\n",
      ". P . P B . . P\n",
      "P . . . K P . .\n",
      "R . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "board = chess.Board()\n",
    "\n",
    "counter = 1\n",
    "\n",
    "while True:\n",
    "    print(\"Move:\",counter, '-'*10)\n",
    "    counter += 1\n",
    "    \n",
    "    # Get Move from Model     \n",
    "    move = get_ai_move(board, 2, \"white\")\n",
    "    board.push(move)\n",
    "    print(f'\\n{board}')\n",
    "    if board.is_game_over():\n",
    "      break\n",
    "    \n",
    "    # Get Move from Stockfish \n",
    "    \n",
    "    fen = board.fen()\n",
    "    stockfish.set_fen_position(fen)\n",
    "    move = stockfish.get_best_move()\n",
    "    move = chess.Move.from_uci(move)\n",
    "    board.push(move)\n",
    "    print(f'\\n{board}')\n",
    "    if board.is_game_over():\n",
    "      break\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g><radialGradient id=\"check_gradient\"><stop offset=\"0%\" stop-color=\"#ff0000\" stop-opacity=\"1.0\" /><stop offset=\"50%\" stop-color=\"#e70000\" stop-opacity=\"1.0\" /><stop offset=\"100%\" stop-color=\"#9e0000\" stop-opacity=\"0.0\" /></radialGradient></defs><rect x=\"0\" y=\"0\" width=\"390\" height=\"390\" fill=\"#212121\" /><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-rook\" transform=\"translate(15, 330)\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-king\" transform=\"translate(195, 285)\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(60, 240)\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(150, 240)\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark lastmove e3\" stroke=\"none\" fill=\"#aaa23b\" /><use xlink:href=\"#white-bishop\" transform=\"translate(195, 240)\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(330, 240)\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-rook\" transform=\"translate(60, 195)\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(105, 195)\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"check\" fill=\"url(#check_gradient)\" /><use xlink:href=\"#black-king\" transform=\"translate(240, 195)\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#white-rook\" transform=\"translate(285, 150)\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#black-pawn\" transform=\"translate(15, 105)\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><use xlink:href=\"#white-pawn\" transform=\"translate(105, 105)\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-rook\" transform=\"translate(240, 105)\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark lastmove a7\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><use xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><g transform=\"translate(20, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g></svg>"
      ],
      "text/plain": [
       "Board('8/2p5/p1P2r2/6R1/1rP2k2/1P1PB2P/P3KP2/R7 b - - 2 39')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "myTensor",
   "language": "python",
   "name": "mytensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
